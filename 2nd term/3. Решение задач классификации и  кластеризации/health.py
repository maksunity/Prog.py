import os
import re
import codecs
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from collections import Counter


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤
def safe_read_file(filepath):
    encodings = ['utf-8', 'cp1252', 'iso-8859-1']
    for enc in encodings:
        try:
            with codecs.open(filepath, 'r', encoding=enc, errors='ignore') as f:
                return f.readlines()
        except Exception as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å {filepath} —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {enc}: {e}")
    return []


# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
folder = "Health-Tweets"  # –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å .txt —Ñ–∞–π–ª–∞–º–∏
texts = []

for filename in os.listdir(folder):
    if filename.endswith(".txt"):
        lines = safe_read_file(os.path.join(folder, filename))
        for line in lines:
            parts = line.strip().split("|")
            if len(parts) >= 3:
                texts.append(parts[2]) # –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ—Å—Ç–∏

print("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤:", len(texts))
cleaned_texts = [re.sub(r"http\S+", "", t) for t in texts]

# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
vectorizer = TfidfVectorizer(stop_words="english", max_df=0.8, min_df=2)
X_tfidf = vectorizer.fit_transform(cleaned_texts)

# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
kmeans = KMeans(n_clusters=5, random_state=42)
labels = kmeans.fit_predict(X_tfidf)

print("\n–¢–æ–ø –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]
terms = vectorizer.get_feature_names_out()

for i in range(kmeans.n_clusters):
    top_terms = [terms[ind] for ind in order_centroids[i, :10]]
    print(f"üîπ –ö–ª–∞—Å—Ç–µ—Ä {i}: {', '.join(top_terms)}")

print("\n–ü—Ä–∏–º–µ—Ä—ã –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º:")
for cluster_id in range(kmeans.n_clusters):
    print(f"\n–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}")
    cluster_texts = [text for i, text in enumerate(texts) if labels[i] == cluster_id]
    for example in cluster_texts[:10]:  # 10 –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        print(f"  - {example}")


pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X_tfidf.toarray())

plt.figure(figsize=(10, 6))
plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=labels, cmap="tab10")
plt.title("–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π –æ –∑–¥–æ—Ä–æ–≤—å–µ")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.show()
